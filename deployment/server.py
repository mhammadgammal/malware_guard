from collections import Counter
import io
import os
from fastapi import FastAPI, UploadFile, File, HTTPException, Request
from fastapi.responses import HTMLResponse, JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
from skimage.feature import hog
from skimage import exposure
import cv2
from PIL import Image
import joblib
import numpy as np

import tensorflow as tf
# from tensorflow.keras.models import load_model
# from tensorflow.keras.preprocessing import image
import keras
from keras._tf_keras.keras.models import load_model
app = FastAPI()

# Define directory paths
static_dir = os.path.join(os.path.dirname(__file__), "static")
templates_dir = os.path.join(os.path.dirname(__file__), "T")
model_path = os.path.join(os.path.dirname(__file__), "svm_model.pkl")
vgg_model_path = os.path.join(os.path.dirname(__file__), "MalwareProject\VGG16_model.h5")

# Mount static directory for serving static files
app.mount("/static", StaticFiles(directory=static_dir), name="static")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=['*'],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Use Jinja2Templates for loading HTML templates
templates = Jinja2Templates(directory=templates_dir)

# Load the machine learning model
model = joblib.load(model_path)
vgg_model = load_model(vgg_model_path)

@app.get("/", response_class=HTMLResponse)
async def index(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})

@app.post("/upload/")
async def upload_file(exe_file: UploadFile = File(...)):
    try:
        # Create uploads directory if it doesn't exist
        uploads_dir = os.path.join(os.path.dirname(__file__), "uploads")
        os.makedirs(uploads_dir, exist_ok=True)

        # Save uploaded file to uploads directory
        filename = os.path.join(uploads_dir, exe_file.filename)
        with open(filename, "wb") as f:
            f.write(exe_file.file.read())

        # Perform conversion
        output_filepath = convert_to_image(filename)

        # Prepare response data
        image_filename = os.path.basename(output_filepath)
        image_path = f"{image_filename}"
        return {"image_path": image_path}

    except (FileNotFoundError, PermissionError) as e:
        return {"error": str(e)}
    except Exception as e:
         return {"error": str(e)}


@app.get("/get_image/{image_name}")
async def get_image(image_name: str):
    # Assuming the image name is passed as a parameter in the URL
    # You can construct the path to the image file based on the image name
    image_path = f"uploads/{image_name}"
    return FileResponse(image_path)


async def pred(image_content: bytes):
    try:
        # Open the image using PIL
        img = Image.open(io.BytesIO(image_content))

        # Perform any preprocessing if necessary

        # Convert the image to a numpy array
        img_array = np.array(img)

        # Perform prediction using the model
        prediction = vgg_model.predict([img_array])
        # Return the prediction result
        return prediction.tolist()  # Convert prediction to list for JSON serializable

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# @app.get("/predict/{image_name}")
async def predict(image_name: str):
    print(image_name)
    try:
        prediction = await select_image(f'uploads/{image_name}')
        return prediction
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/show/", response_class=HTMLResponse)
async def show_image(request: Request, image_path: str):
    return templates.TemplateResponse("show.html", {"request": request, "image_path": image_path})


def convert_to_image(input_file):
    try:
        output_filepath = os.path.splitext(input_file)[0] + "_output.png"

        with open(input_file, 'rb') as file:
            binary_data = file.read()

        data_size = len(binary_data)
        image_width = int(data_size ** 0.5) + 1
        image_height = (data_size // image_width) + 1

        image = Image.new('RGB', (image_width, image_height))
        pixels = image.load()

        index = 0
        for y in range(image_height):
            for x in range(image_width):
                if index < data_size:
                    byte_value = binary_data[index]
                    pixels[x, y] = (byte_value, byte_value, byte_value)
                    index += 1

        image.save(output_filepath)
        return output_filepath

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error converting file: {e}")

async def select_image(file_path):
        pred=''
        test_dataset_root = os.path.join('E:/University/GP/MalwareGuard/src/MalwareGuard/train and test/test')
        test_data, test_labels = load_data_and_labels(test_dataset_root)
        loaded_models = load_models('E:/University/GP/MalwareGuard/src/MalwareGuard/saved_models')
        for model_name, model in loaded_models.items():
            predictions = model.predict(test_data)
            # accuracy = accuracy_score(test_labels, predictions)
            print(f'Accuracy of {model_name}')
        if file_path:
            predicted_classes = predict_image_class(file_path, load_models('E:/University/GP/MalwareGuard/src/MalwareGuard/saved_models'))
            pred = f"Predicted Classes: {predicted_classes}, "
            print(pred)

            if predicted_classes == "Rogue":
                return pred + "family is Fakerean"
            elif predicted_classes == "Worms":
                worms_dir = 'E:/University/GP/MalwareGuard/src/MalwareGuard/saved_models_Worms'
                loaded_models_worms = load_models(worms_dir)
                return pred + f"Predicted Family is: {predict_image_class_Worms(file_path, loaded_models_worms)}"
            elif predicted_classes == "Trojan":
                Trojan_dir = 'E:/University/GP/MalwareGuard/src/MalwareGuard/saved_models_Trojan'
                loaded_models_Trojan = load_models(Trojan_dir)
                return pred + f"Predicted Family is: {predict_image_class_Trojan(file_path, loaded_models_Trojan)}"
            elif predicted_classes == "Backdoor":
                Backdoor_dir = 'E:/University/GP/MalwareGuard/src/MalwareGuard/saved_models_Backdoor'
                loaded_models_Backdoor = load_models(Backdoor_dir)
                return pred + f"Predicted Family is: {predict_image_class_Backdoor(file_path, loaded_models_Backdoor)}"
            elif predicted_classes == "PWS":
                PWS_dir = 'E:/University/GP/MalwareGuard/src/MalwareGuard/saved_models_PWS'
                loaded_models_PWS = load_models(PWS_dir)
                return pred + f"Predicted Family is: {predict_image_class_PWS(file_path, loaded_models_PWS)}"
            elif predicted_classes == "TDownloader":
                TDownloader_dir = 'E:/University/GP/MalwareGuard/src/MalwareGuard/saved_models_TDownloader'
                loaded_models_TDownloader = load_models(TDownloader_dir)
                return pred + f"Predicted Family is: {predict_image_class_TDownloader(file_path, loaded_models_TDownloader)}"
            elif predicted_classes == "Dialer":
                Dialer_dir = 'E:/University/GP/MalwareGuard/src/MalwareGuard/saved_models_Dialer'
                loaded_models_Dialer = load_models(Dialer_dir)
                return pred + f"Predicted Family is: {predict_image_class_Dialer(file_path, loaded_models_Dialer)}"

def load_models(model_dir):
    models = {}
    for model_file in os.listdir(model_dir):
        if model_file.endswith('.pkl'):
            model_name = os.path.splitext(model_file)[0]
            models[model_name] = joblib.load(os.path.join(model_dir, model_file))
    return models


def predict_image_class(image_path, models):
    preprocessed_image_features = preprocess_image(image_path)
    predicted_classes = []
    print(models)

    # Predict using each model and store the predictions
    for model_name, model in models.items():
        predicted_class = model.predict([preprocessed_image_features])
        print(predicted_class)
        predicted_classes.append(predicted_class[0])  # Append the predicted class

    # Count occurrences of each predicted class
    class_counts = Counter(predicted_classes)
    print(predicted_classes)

    most_frequent_class = class_counts.most_common(1)[0][0]

    l = ["Backdoor", "Dialer", "PWS", "Rogue", "TDownloader", "Trojan", "Worms"]
    print(most_frequent_class)

    return l[most_frequent_class]

def predict_image_class_Dialer(image_path, models):

    preprocessed_image_features = preprocess_image(image_path)
    predicted_classes = []

    # Predict using each model and store the predictions
    for model_name, model in models.items():
        predicted_class = model.predict([preprocessed_image_features])
        predicted_classes.append(predicted_class[0])  # Append the predicted class

    # Count occurrences of each predicted class
    class_counts = Counter(predicted_classes)

    most_frequent_class = class_counts.most_common(1)[0][0]

    l = ["Adialer.C","Dialplatform.B","Instantaccess"]




    return l[most_frequent_class]

def predict_image_class_PWS(image_path, models):

    preprocessed_image_features = preprocess_image(image_path)
    predicted_classes = []

    # Predict using each model and store the predictions
    for model_name, model in models.items():
        predicted_class = model.predict([preprocessed_image_features])
        predicted_classes.append(predicted_class[0])  # Append the predicted class

    # Count occurrences of each predicted class
    class_counts = Counter(predicted_classes)

    most_frequent_class = class_counts.most_common(1)[0][0]

    l = ["Lolyda.AA1", "Lolyda.AA2", "Lolyda.AA3", "Lolyda.AT"]




    return l[most_frequent_class]

def predict_image_class_Backdoor(image_path, models):

    preprocessed_image_features = preprocess_image(image_path)
    predicted_classes = []

    # Predict using each model and store the predictions
    for model_name, model in models.items():
        predicted_class = model.predict([preprocessed_image_features])
        predicted_classes.append(predicted_class[0])  # Append the predicted class

    # Count occurrences of each predicted class
    class_counts = Counter(predicted_classes)

    most_frequent_class = class_counts.most_common(1)[0][0]

    l = ["Agent.FYI", "Rbot!gen"]




    return l[most_frequent_class]

def predict_image_class_Worms(image_path, models):

    preprocessed_image_features = preprocess_image(image_path)
    predicted_classes = []

    # Predict using each model and store the predictions
    for model_name, model in models.items():
        predicted_class = model.predict([preprocessed_image_features])
        predicted_classes.append(predicted_class[0])  # Append the predicted class

    # Count occurrences of each predicted class
    class_counts = Counter(predicted_classes)

    most_frequent_class = class_counts.most_common(1)[0][0]

    l = ["Allaple.A", "Allaple.L", "Autorun.K", "VB.AT", "Yuner.A"]




    return l[most_frequent_class]

def predict_image_class_Trojan(image_path, models):

    preprocessed_image_features = preprocess_image(image_path)
    predicted_classes = []

    # Predict using each model and store the predictions
    for model_name, model in models.items():
        predicted_class = model.predict([preprocessed_image_features])
        predicted_classes.append(predicted_class[0])  # Append the predicted class

    # Count occurrences of each predicted class
    class_counts = Counter(predicted_classes)

    most_frequent_class = class_counts.most_common(1)[0][0]

    l = ["Alueron.gen!J", "C2LOP.gen!g", "C2LOP.P", "Malex.gen!J", "Skintrim.N"]




    return l[most_frequent_class]

def predict_image_class_TDownloader(image_path, models):

    preprocessed_image_features = preprocess_image(image_path)
    predicted_classes = []

    # Predict using each model and store the predictions
    for model_name, model in models.items():
        predicted_class = model.predict([preprocessed_image_features])
        predicted_classes.append(predicted_class[0])  # Append the predicted class

    # Count occurrences of each predicted class
    class_counts = Counter(predicted_classes)

    most_frequent_class = class_counts.most_common(1)[0][0]

    l = ["Dontovo.A", "Obfuscator.AD", "Swizzor.gen!E", "Swizzor.gen!I", "Wintrim.BX"]




    return l[most_frequent_class]
def preprocess_image(image_path):
    # Read image
    img = cv2.imread(image_path)
    # Convert to grayscale
    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # Resize
    img_resized = cv2.resize(img_gray, (128, 64))
    # Extract HOG features
    features = hog(img_resized, orientations=8, pixels_per_cell=(8, 8),
                   cells_per_block=(1, 1), visualize=False)
    # Enhance contrast
    features = exposure.rescale_intensity(features, in_range=(0, 10))
    return features

def load_data_and_labels(root_path):
    data = []
    labels = []
    label_encoder = LabelEncoder()

    for family in os.listdir(root_path):
        family_path = os.path.join(root_path, family)

        for file_name in os.listdir(family_path):
            file_path = os.path.join(family_path, file_name)

            # Check if the item in the folder is a file
            for class_name in os.listdir(file_path):
                class_path = os.path.join(file_path, class_name)
                if os.path.isfile(class_path):
                    # Load image
                    img = cv2.imread(class_path)

                    # Convert to grayscale and resize
                    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
                    img_resized = cv2.resize(img_gray, (128, 64))  # Resize for consistency

                    # Extract HOG features
                    features = hog(img_resized, orientations=8, pixels_per_cell=(8, 8),
                                   cells_per_block=(1, 1), visualize=False)

                    # Enhance the contrast of the HOG features
                    features = exposure.rescale_intensity(features, in_range=(0, 10))

                    data.append(features)
                    labels.append(family)

    # Encode categorical labels into numerical format
    encoded_labels = label_encoder.fit_transform(labels)

    return data, encoded_labels
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)
